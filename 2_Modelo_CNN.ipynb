{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d54f5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import get_class, plot_to_tensorboard, evaluate, param_counter, CNNClassifier\n",
    "from CustomImageDataset import CustomImageDataset\n",
    "from MLPClassifier import MLPClassifier\n",
    "\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02f6b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5934bf",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "> Cargar imagenes al dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "491ee4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'data/Split_smol/train/'\n",
    "p = Path(data_dir).glob('**/*')\n",
    "files = [(x, get_class(x), Image.open(x).size,Image.open(x)) for x in p if x.is_file()]\n",
    "df_train = pd.DataFrame(files, columns=[\"path\", \"class\", \"resolution\",\"data\"])\n",
    "\n",
    "data_dir = r'data/Split_smol/val/'\n",
    "p = Path(data_dir).glob('**/*')\n",
    "files = [(x, get_class(x), Image.open(x).size,Image.open(x)) for x in p if x.is_file()]\n",
    "df_val = pd.DataFrame(files, columns=[\"path\", \"class\", \"resolution\", \"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e8c9c",
   "metadata": {},
   "source": [
    "## Modelo para clasificación de imágenes con MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fe56dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/ivan/ITBA/Redes/RN-TP1/mlruns/779117040822828427', creation_time=1751074950104, experiment_id='779117040822828427', last_update_time=1751074950104, lifecycle_stage='active', name='CNN_Clasificador_Imagenes', tags={}>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"CNN_Clasificador_Imagenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53c2e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definitions\n",
    "\n",
    "TRAIN_DIR = \"data/Split_smol/train/\"\n",
    "VAL_DIR = \"data/Split_smol/val/\"\n",
    "\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea264742",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_space= {\n",
    "    \"model\": (\"MLPClassifier\"),\n",
    "    \"input_size\":  [32,64,128],\n",
    "    \"batch_size\": [16,32],\n",
    "    \"lr\": [1e-3,1e-4],\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\":  [\"Adam\"],\n",
    "    \"HFlip\": [0.0,0.5],\n",
    "    \"VFlip\": [0.0,0.5],\n",
    "    \"RBContrast\": [0.0, 0.5],\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"train_dir\": TRAIN_DIR,\n",
    "    \"val_dir\": VAL_DIR,\n",
    "    \"es_patience\": 10,\n",
    "    \"dropout\": [0.0,0.1,0.2,0.3],\n",
    "    \"kernel_size\": [3,4],\n",
    "    \"out_channels\": [8,16,24]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bfa6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_size = hparams_space[\"input_size\"][1]\n",
    "horizontal_flip = hparams_space[\"HFlip\"][1]\n",
    "RBContrast = hparams_space[\"RBContrast\"][1]\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(transform_size, transform_size),\n",
    "    A.HorizontalFlip(p=horizontal_flip),\n",
    "    A.RandomBrightnessContrast(p=RBContrast),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_test_transform = A.Compose([\n",
    "    A.Resize(transform_size, transform_size),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ca487cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomImageDataset(TRAIN_DIR, transform=train_transform)\n",
    "val_dataset   = CustomImageDataset(VAL_DIR, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model = CNNClassifier(input_size=transform_size ,num_classes=num_classes, dropout=hparams_space[\"dropout\"][1]).to(device)\n",
    "# model.init_weights()\n",
    "\n",
    "log_dir = \"runs/mlp_experimento_1\"\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133951be",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2afd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelo número: 0\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'label_encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m train_loss = running_loss / \u001b[38;5;28mlen\u001b[39m(train_loader)\n\u001b[32m     86\u001b[39m train_acc = \u001b[32m100.0\u001b[39m * correct / total\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m val_loss, val_acc = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabel_encoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m#print(f\"Epoch {epoch+1}:\")\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m#print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m#print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\u001b[39;00m\n\u001b[32m     93\u001b[39m writer.add_scalar(\u001b[33m\"\u001b[39m\u001b[33mtrain/loss\u001b[39m\u001b[33m\"\u001b[39m, train_loss, epoch)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITBA/Redes/RN-TP1/utils.py:72\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, loader, writer, device, train_dataset, criterion, epoch, prefix)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(model, loader, writer, device, train_dataset, criterion, epoch=\u001b[38;5;28;01mNone\u001b[39;00m, prefix=\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[43mlog_classification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mval\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m     model.eval()\n\u001b[32m     74\u001b[39m     correct, total, loss_sum = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0.0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITBA/Redes/RN-TP1/utils.py:49\u001b[39m, in \u001b[36mlog_classification_report\u001b[39m\u001b[34m(model, device, train_dataset, loader, writer, step, prefix)\u001b[39m\n\u001b[32m     47\u001b[39m cm = confusion_matrix(all_labels, all_preds)\n\u001b[32m     48\u001b[39m fig_cm, ax = plt.subplots(figsize=(\u001b[32m6\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=\u001b[43mtrain_dataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlabel_encoder\u001b[49m.classes_)\n\u001b[32m     50\u001b[39m disp.plot(ax=ax, cmap=\u001b[33m'\u001b[39m\u001b[33mBlues\u001b[39m\u001b[33m'\u001b[39m, xticks_rotation=\u001b[32m45\u001b[39m)\n\u001b[32m     51\u001b[39m ax.set_title(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix.title()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - Confusion Matrix\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'label_encoder'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelnbr = 0\n",
    "for input_size in hparams_space[\"input_size\"]:\n",
    "    for batch_size in hparams_space[\"batch_size\"]:\n",
    "        for lr in hparams_space[\"lr\"]:\n",
    "            for optimizer in hparams_space[\"optimizer\"]:\n",
    "                for HFlip in hparams_space[\"HFlip\"]:\n",
    "                    for VFlip in hparams_space[\"VFlip\"]:\n",
    "                        for RBContrast in hparams_space[\"RBContrast\"]:\n",
    "                            for dropout in hparams_space[\"dropout\"]:\n",
    "                                for kernel_size in hparams_space[\"kernel_size\"]:\n",
    "                                    for out_channels in hparams_space[\"out_channels\"]:\n",
    "                                        if True: #np.random.rand() < 0.05:\n",
    "                                            print(f\"modelo número: {modelnbr}\", end = \"\\r\")\n",
    "                                            modelnbr += 1\n",
    "                                            hparams= {\n",
    "                                                \"model\": (\"CNNClassifier\"),\n",
    "                                                \"input_size\":  input_size,\n",
    "                                                \"batch_size\": batch_size,\n",
    "                                                \"lr\": lr,\n",
    "                                                \"epochs\": 200,\n",
    "                                                \"optimizer\": optimizer,\n",
    "                                                \"HFlip\": HFlip,\n",
    "                                                \"VFlip\": VFlip,\n",
    "                                                \"RBContrast\": RBContrast,\n",
    "                                                \"loss_fn\": \"CrossEntropyLoss\",\n",
    "                                                \"train_dir\": TRAIN_DIR,\n",
    "                                                \"val_dir\": VAL_DIR,\n",
    "                                                \"es_patience\": 10,\n",
    "                                                \"dropout\": dropout,\n",
    "                                                \"kernel_size\": kernel_size,\n",
    "                                                \"out_channels\": out_channels,\n",
    "                                                \"model_number\": modelnbr\n",
    "                                            }\n",
    "                                            train_transform = A.Compose([\n",
    "                                                A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                                A.HorizontalFlip(p=hparams[\"HFlip\"]),\n",
    "                                                A.VerticalFlip(p=hparams[\"VFlip\"]),\n",
    "                                                A.RandomBrightnessContrast(p=hparams[\"RBContrast\"]),\n",
    "                                                A.Normalize(),\n",
    "                                                ToTensorV2()\n",
    "                                            ])\n",
    "                                            val_test_transform = A.Compose([\n",
    "                                                A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                                A.Normalize(),\n",
    "                                                ToTensorV2()\n",
    "                                            ])\n",
    "                                            train_dataset = CustomImageDataset(hparams[\"train_dir\"], transform=train_transform)\n",
    "                                            val_dataset   = CustomImageDataset(hparams['val_dir'], transform=val_test_transform)\n",
    "                                            batch_size = hparams[\"batch_size\"]\n",
    "                                            train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                            val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                                            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                                            num_classes = len(set(train_dataset.labels))\n",
    "                                            model = CNNClassifier(num_classes=num_classes, input_size = hparams[\"input_size\"], dropout = hparams[\"dropout\"], kernel_size=hparams[\"kernel_size\"],out_channels=hparams[\"out_channels\"]).to(device)\n",
    "                                            criterion = nn.CrossEntropyLoss()\n",
    "                                            optimizer = optim.Adam(model.parameters(), lr=hparams[\"lr\"]) if hparams[\"optimizer\"]==\"Adam\" else optim.SGD(model.parameters(), lr=hparams[\"lr\"])\n",
    "                                            hparams[\"count_params\"] = param_counter(model)\n",
    "                                            with mlflow.start_run():\n",
    "                                                # Log hiperparámetros\n",
    "                                                mlflow.log_params(hparams)\n",
    "                                                best_val_acc = 0\n",
    "                                                best_val_loss = 0\n",
    "                                                best_train_acc = 0\n",
    "                                                best_train_loss = 0\n",
    "                                                best_epoch = 0\n",
    "                                                for epoch in range(hparams[\"epochs\"]):\n",
    "                                                    model.train()\n",
    "                                                    running_loss = 0.0\n",
    "                                                    correct, total = 0, 0\n",
    "                                                \n",
    "                                                    for images, labels in train_loader:\n",
    "                                                        images, labels = images.to(device), labels.to(device)\n",
    "                                                \n",
    "                                                        optimizer.zero_grad()\n",
    "                                                        outputs = model(images)\n",
    "                                                        loss = criterion(outputs, labels)\n",
    "                                                        loss.backward()\n",
    "                                                        optimizer.step()\n",
    "                                                \n",
    "                                                        running_loss += loss.item()\n",
    "                                                        _, preds = torch.max(outputs, 1)\n",
    "                                                        correct += (preds == labels).sum().item()\n",
    "                                                        total += labels.size(0)\n",
    "                                                \n",
    "                                                    train_loss = running_loss / len(train_loader)\n",
    "                                                    train_acc = 100.0 * correct / total\n",
    "                                                    val_loss, val_acc = evaluate(model, val_loader, writer, device,train_dataset,criterion,epoch=epoch, prefix=\"val\")\n",
    "                                                \n",
    "                                                    #print(f\"Epoch {epoch+1}:\")\n",
    "                                                    #print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "                                                    #print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "                                                \n",
    "                                                    writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "                                                    writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "                                                \n",
    "                                                    # Log en MLflow\n",
    "                                                    mlflow.log_metrics({\n",
    "                                                        \"train_loss\": train_loss,\n",
    "                                                        \"train_accuracy\": train_acc,\n",
    "                                                        \"val_loss\": val_loss,\n",
    "                                                        \"val_accuracy\": val_acc\n",
    "                                                    }, step=epoch)\n",
    "                                                    if val_acc > best_val_acc:\n",
    "                                                        best_val_acc = val_acc\n",
    "                                                        best_val_loss = val_loss\n",
    "                                                        best_train_acc = train_acc\n",
    "                                                        best_train_loss = train_loss\n",
    "                                                        best_epoch = epoch\n",
    "                                                        # Guardar modelo\n",
    "                                                        torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "                                                        #print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "                                                        mlflow.log_artifact(\"mlp_model.pth\")\n",
    "                                                        mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "                                                    elif epoch > best_epoch + hparams[\"es_patience\"]:\n",
    "                                                        #print(\"Early Stopping\")\n",
    "                                                        break\n",
    "                                                        \n",
    "                                                mlflow.log_metrics({\n",
    "                                                        \"train_loss\": best_train_loss,\n",
    "                                                        \"train_accuracy\": best_train_acc,\n",
    "                                                        \"val_loss\": best_val_loss,\n",
    "                                                        \"val_accuracy\": best_val_acc,\n",
    "                                                        \"best_epoch\": best_epoch\n",
    "                                                    }, step=epoch+1)                                                \n",
    "                                                \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
