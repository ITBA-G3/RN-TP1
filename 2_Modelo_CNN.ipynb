{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d54f5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import get_class, plot_to_tensorboard, evaluate, param_counter, CNNClassifier\n",
    "from CustomImageDataset import CustomImageDataset\n",
    "from MLPClassifier import MLPClassifier\n",
    "\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02f6b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "logging.getLogger(\"mlflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5934bf",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "> Cargar imagenes al dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "491ee4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r'data/Split_smol/train/'\n",
    "p = Path(data_dir).glob('**/*')\n",
    "files = [(x, get_class(x), Image.open(x).size,Image.open(x)) for x in p if x.is_file()]\n",
    "df_train = pd.DataFrame(files, columns=[\"path\", \"class\", \"resolution\",\"data\"])\n",
    "\n",
    "data_dir = r'data/Split_smol/val/'\n",
    "p = Path(data_dir).glob('**/*')\n",
    "files = [(x, get_class(x), Image.open(x).size,Image.open(x)) for x in p if x.is_file()]\n",
    "df_val = pd.DataFrame(files, columns=[\"path\", \"class\", \"resolution\", \"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70e8c9c",
   "metadata": {},
   "source": [
    "## Modelo para clasificación de imágenes con MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fe56dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/herstegen/ITBA/redes/RN-TP1/mlruns/694304783691286067', creation_time=1751125708123, experiment_id='694304783691286067', last_update_time=1751125708123, lifecycle_stage='active', name='CNN_HP_ya_calculados', tags={}>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"CNN_HP_ya_calculados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53c2e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant definitions\n",
    "\n",
    "TRAIN_DIR = \"data/Split_smol/train/\"\n",
    "VAL_DIR = \"data/Split_smol/val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ea264742",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams= {\n",
    "    \"model\": (\"MLPClassifier\"),\n",
    "    \"input_size\":  100,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 1e-3,\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\":  \"Adam\",\n",
    "    \"HFlip\": 0.5,\n",
    "    \"VFlip\": 0.5,\n",
    "    \"RBContrast\": 0.5,\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"train_dir\": TRAIN_DIR,\n",
    "    \"val_dir\": VAL_DIR,\n",
    "    \"es_patience\": 10,\n",
    "    \"dropout\": 0.1,\n",
    "    \"kernel_size\": 2,\n",
    "    \"out_channels\": 30\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ca487cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"runs/CNN_HP_ya_calculados\"\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133951be",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cf2afd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "  Train Loss: 2.0323, Accuracy: 28.69%\n",
      "  Val   Loss: 1.6011, Accuracy: 38.67%\n",
      "Epoch 2:\n",
      "  Train Loss: 1.4620, Accuracy: 44.91%\n",
      "  Val   Loss: 1.4647, Accuracy: 43.09%\n",
      "Epoch 3:\n",
      "  Train Loss: 1.2646, Accuracy: 53.37%\n",
      "  Val   Loss: 1.2046, Accuracy: 54.14%\n",
      "Epoch 4:\n",
      "  Train Loss: 1.1090, Accuracy: 59.11%\n",
      "  Val   Loss: 1.2216, Accuracy: 53.04%\n",
      "Epoch 5:\n",
      "  Train Loss: 0.9940, Accuracy: 62.27%\n",
      "  Val   Loss: 1.1508, Accuracy: 53.04%\n",
      "Epoch 6:\n",
      "  Train Loss: 0.9192, Accuracy: 66.14%\n",
      "  Val   Loss: 1.2282, Accuracy: 51.93%\n",
      "Epoch 7:\n",
      "  Train Loss: 0.8895, Accuracy: 66.43%\n",
      "  Val   Loss: 1.0311, Accuracy: 61.33%\n",
      "Epoch 8:\n",
      "  Train Loss: 0.8761, Accuracy: 67.58%\n",
      "  Val   Loss: 1.1385, Accuracy: 53.59%\n",
      "Epoch 9:\n",
      "  Train Loss: 0.8508, Accuracy: 68.87%\n",
      "  Val   Loss: 1.0602, Accuracy: 55.25%\n",
      "Epoch 10:\n",
      "  Train Loss: 0.7555, Accuracy: 72.02%\n",
      "  Val   Loss: 1.0840, Accuracy: 56.91%\n",
      "Epoch 11:\n",
      "  Train Loss: 0.7623, Accuracy: 73.17%\n",
      "  Val   Loss: 1.0141, Accuracy: 61.33%\n",
      "Epoch 12:\n",
      "  Train Loss: 0.7411, Accuracy: 73.31%\n",
      "  Val   Loss: 1.0274, Accuracy: 58.56%\n",
      "Epoch 13:\n",
      "  Train Loss: 0.6928, Accuracy: 73.60%\n",
      "  Val   Loss: 0.9814, Accuracy: 62.43%\n",
      "Epoch 14:\n",
      "  Train Loss: 0.7024, Accuracy: 73.74%\n",
      "  Val   Loss: 1.0434, Accuracy: 60.77%\n",
      "Epoch 15:\n",
      "  Train Loss: 0.6811, Accuracy: 75.47%\n",
      "  Val   Loss: 1.0151, Accuracy: 60.22%\n",
      "Epoch 16:\n",
      "  Train Loss: 0.6072, Accuracy: 77.47%\n",
      "  Val   Loss: 1.0334, Accuracy: 58.56%\n",
      "Epoch 17:\n",
      "  Train Loss: 0.6002, Accuracy: 78.05%\n",
      "  Val   Loss: 0.9346, Accuracy: 62.43%\n",
      "Epoch 18:\n",
      "  Train Loss: 0.5706, Accuracy: 80.06%\n",
      "  Val   Loss: 1.0954, Accuracy: 62.43%\n",
      "Epoch 19:\n",
      "  Train Loss: 0.5516, Accuracy: 78.77%\n",
      "  Val   Loss: 0.9738, Accuracy: 60.77%\n",
      "Epoch 20:\n",
      "  Train Loss: 0.5262, Accuracy: 80.63%\n",
      "  Val   Loss: 1.0577, Accuracy: 59.12%\n",
      "Epoch 21:\n",
      "  Train Loss: 0.5407, Accuracy: 78.77%\n",
      "  Val   Loss: 1.0226, Accuracy: 60.77%\n",
      "Epoch 22:\n",
      "  Train Loss: 0.4740, Accuracy: 82.35%\n",
      "  Val   Loss: 1.0061, Accuracy: 62.43%\n",
      "Epoch 23:\n",
      "  Train Loss: 0.4364, Accuracy: 83.50%\n",
      "  Val   Loss: 1.0379, Accuracy: 65.75%\n",
      "Epoch 24:\n",
      "  Train Loss: 0.4528, Accuracy: 83.21%\n",
      "  Val   Loss: 1.1060, Accuracy: 62.98%\n",
      "Epoch 25:\n",
      "  Train Loss: 0.4136, Accuracy: 85.80%\n",
      "  Val   Loss: 1.1322, Accuracy: 64.09%\n",
      "Epoch 26:\n",
      "  Train Loss: 0.4903, Accuracy: 82.64%\n",
      "  Val   Loss: 1.0172, Accuracy: 64.64%\n",
      "Epoch 27:\n",
      "  Train Loss: 0.4041, Accuracy: 84.94%\n",
      "  Val   Loss: 1.0541, Accuracy: 61.88%\n",
      "Epoch 28:\n",
      "  Train Loss: 0.3622, Accuracy: 86.66%\n",
      "  Val   Loss: 1.0045, Accuracy: 65.75%\n",
      "Epoch 29:\n",
      "  Train Loss: 0.3613, Accuracy: 87.66%\n",
      "  Val   Loss: 1.0287, Accuracy: 64.09%\n",
      "Epoch 30:\n",
      "  Train Loss: 0.3786, Accuracy: 86.94%\n",
      "  Val   Loss: 1.0619, Accuracy: 65.19%\n",
      "Epoch 31:\n",
      "  Train Loss: 0.3355, Accuracy: 88.81%\n",
      "  Val   Loss: 1.0668, Accuracy: 65.19%\n",
      "Epoch 32:\n",
      "  Train Loss: 0.3025, Accuracy: 89.10%\n",
      "  Val   Loss: 1.1080, Accuracy: 64.64%\n",
      "Epoch 33:\n",
      "  Train Loss: 0.2954, Accuracy: 90.24%\n",
      "  Val   Loss: 1.1434, Accuracy: 62.98%\n",
      "Epoch 34:\n",
      "  Train Loss: 0.2658, Accuracy: 90.39%\n",
      "  Val   Loss: 1.2133, Accuracy: 64.09%\n"
     ]
    }
   ],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "    A.HorizontalFlip(p=hparams[\"HFlip\"]),\n",
    "    A.VerticalFlip(p=hparams[\"VFlip\"]),\n",
    "    A.RandomBrightnessContrast(p=hparams[\"RBContrast\"]),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "val_test_transform = A.Compose([\n",
    "    A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "train_dataset = CustomImageDataset(hparams[\"train_dir\"], transform=train_transform)\n",
    "val_dataset   = CustomImageDataset(hparams['val_dir'], transform=val_test_transform)\n",
    "batch_size = hparams[\"batch_size\"]\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_classes = len(set(train_dataset.labels))\n",
    "model = CNNClassifier(num_classes=num_classes, input_size = hparams[\"input_size\"], dropout = hparams[\"dropout\"], kernel_size=hparams[\"kernel_size\"],out_channels=hparams[\"out_channels\"]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.NAdam(model.parameters(), lr=hparams[\"lr\"]) if hparams[\"optimizer\"]==\"Adam\" else optim.SGD(model.parameters(), lr=hparams[\"lr\"])\n",
    "hparams[\"count_params\"] = param_counter(model)\n",
    "with mlflow.start_run():\n",
    "    # Log hiperparámetros\n",
    "    mlflow.log_params(hparams)\n",
    "    best_val_acc = 0\n",
    "    best_val_loss = 0\n",
    "    best_train_acc = 0\n",
    "    best_train_loss = 0\n",
    "    best_epoch = 0\n",
    "    for epoch in range(hparams[\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "    \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "        val_loss, val_acc = evaluate(model, val_loader, writer, device,train_dataset,criterion,epoch=epoch, prefix=\"val\")\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "        print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "    \n",
    "        writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "        writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "    \n",
    "        # Log en MLflow\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss,\n",
    "            \"val_accuracy\": val_acc\n",
    "        }, step=epoch)\n",
    "\n",
    "        del images, labels, outputs, preds      #intentamos no acumular memoria RAM\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_val_loss = val_loss\n",
    "            best_train_acc = train_acc\n",
    "            best_train_loss = train_loss\n",
    "            best_epoch = epoch\n",
    "            # Guardar modelo\n",
    "            torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "            #print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "            mlflow.log_artifact(\"mlp_model.pth\")\n",
    "            mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "        elif epoch > best_epoch + hparams[\"es_patience\"]:\n",
    "            #print(\"Early Stopping\")\n",
    "            break\n",
    "            \n",
    "    mlflow.log_metrics({\n",
    "            \"train_loss\": best_train_loss,\n",
    "            \"train_accuracy\": best_train_acc,\n",
    "            \"val_loss\": best_val_loss,\n",
    "            \"val_accuracy\": best_val_acc,\n",
    "            \"best_epoch\": best_epoch\n",
    "        }, step=epoch+1)      \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c508c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
